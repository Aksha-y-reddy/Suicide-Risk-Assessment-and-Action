#openaiPipeline.py
import os
from dotenv import load_dotenv
from tenacity import retry, wait_random_exponential, stop_after_attempt
import openai

load_dotenv()

# OpenAI configuration
GPT_MODEL = "gpt-3.5-turbo"
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")
openai.api_key = OPENAI_API_KEY
    
# Retry strategy for API requests
@retry(wait=wait_random_exponential(multiplier=1, max=40), stop=stop_after_attempt(3))
def analyze_response(question, user_response):
    try:
        # Prepare the prompt with the question and user's response
        prompt = f"Given the question: '{question}'\n\nUser's response: '{user_response}'\n\nAnalyze the user's response and categorize it into Yes, No, or Not Clear based on the implication of the response. Provide your analysis in the format: 'Bot: [analysis result]'"
        response = openai.ChatCompletion.create(
            model=GPT_MODEL,
            messages=[
                {"role": "system", "content": prompt},
            ],
            max_tokens=1000,
            temperature=0.5,
            stop=None,
        )
        # The analysis result is generated by the GPT model based on the prompt
        analysis_result = response.choices[0].message.content
        return analysis_result
    except Exception as e:
        print(f"Exception: {e}")
        return "Bot: Error in analysis"